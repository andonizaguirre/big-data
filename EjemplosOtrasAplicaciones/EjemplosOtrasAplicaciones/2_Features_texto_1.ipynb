{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_Features_texto_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JRigDdEjC7HO"},"source":["# Herramientas para procesamiento de texto (parte 1)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTDF27l9xbzl","executionInfo":{"status":"ok","timestamp":1637718217656,"user_tz":300,"elapsed":3354,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"83d2c054-81bf-4a04-f388-a238000583c6"},"source":["# Solo si se usa Google Colab\n","!pip install pyspark"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n","Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"]}]},{"cell_type":"code","metadata":{"id":"uCob_gIIxesu","executionInfo":{"status":"ok","timestamp":1637718224525,"user_tz":300,"elapsed":6871,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}}},"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName('ejemplo_features1').getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pp6NzT1uxkIo","executionInfo":{"status":"ok","timestamp":1637718230913,"user_tz":300,"elapsed":6391,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"8ac33c8c-fcf9-467c-c86c-ad4fcfbecd42"},"source":["df = spark.createDataFrame(\n","    [(0, 'Hola esta prueba es en el año 2021'),\n","     (1, 'Spark permite clasificación, regresión, etc.'),\n","     (2, 'Los,modelos,de,regresión,usan,datos,numéricos')\n","    ],\n","    ['ID', 'oracion']\n","    )\n","\n","df.show(truncate=False)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+\n","|ID |oracion                                      |\n","+---+---------------------------------------------+\n","|0  |Hola esta prueba es en el año 2021           |\n","|1  |Spark permite clasificación, regresión, etc. |\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|\n","+---+---------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"B9PB4-KRDHR0"},"source":["### Tokenizer\n","\n","La \"tokenización\" (tokenization) es el proceso de tomar texto como entrada y dividirlo en términos individuales, usualmente palabras. "]},{"cell_type":"code","metadata":{"id":"bzi3-xJUyDWV","executionInfo":{"status":"ok","timestamp":1637718230914,"user_tz":300,"elapsed":12,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}}},"source":["from pyspark.ml.feature import Tokenizer, RegexTokenizer\n","from pyspark.sql.functions import udf, col\n","from pyspark.sql.types import IntegerType"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rSDu4VDyaK0","executionInfo":{"status":"ok","timestamp":1637718232448,"user_tz":300,"elapsed":1544,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"94310da9-e81a-495c-cc01-561cf4020ede"},"source":["# Tokenizer por defecto (separa según espacios)\n","tokenizer = Tokenizer(inputCol='oracion', outputCol='palabras')\n","\n","# Aplicar la tokenización a los datos\n","df2 = tokenizer.transform(df)\n","\n","df2.show(truncate=False)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+--------------------------------------------------+\n","|ID |oracion                                      |palabras                                          |\n","+---+---------------------------------------------+--------------------------------------------------+\n","|0  |Hola esta prueba es en el año 2021           |[hola, esta, prueba, es, en, el, año, 2021]       |\n","|1  |Spark permite clasificación, regresión, etc. |[spark, permite, clasificación,, regresión,, etc.]|\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|[los,modelos,de,regresión,usan,datos,numéricos]   |\n","+---+---------------------------------------------+--------------------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MpmZeyXIy-SF","executionInfo":{"status":"ok","timestamp":1637718233776,"user_tz":300,"elapsed":1330,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"0c90b0fc-cb38-4cd7-9e44-28c21079a135"},"source":["# Función definida por el usuario (UDF) para contar el número de palabras (tokens)\n","#     formato:  (funcion, tipo_retornado)\n","countTokens = udf(lambda x: len(x), IntegerType())\n","\n","# Crear una nueva columna \"ntokens\" que muestra el número de tokens (palabras)\n","df2.withColumn('ntokens', countTokens(col('palabras'))).show()"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+--------------------+-------+\n","| ID|             oracion|            palabras|ntokens|\n","+---+--------------------+--------------------+-------+\n","|  0|Hola esta prueba ...|[hola, esta, prue...|      8|\n","|  1|Spark permite cla...|[spark, permite, ...|      5|\n","|  2|Los,modelos,de,re...|[los,modelos,de,r...|      1|\n","+---+--------------------+--------------------+-------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5Vr9qkU0k45","executionInfo":{"status":"ok","timestamp":1637718234357,"user_tz":300,"elapsed":584,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"ee5207dd-8b32-4976-9b16-c7788850049d"},"source":["# Tokenizer usando expresiones regulares (útil para el \"español\")\n","regexTokenizer = RegexTokenizer(inputCol='oracion', outputCol='palabras', pattern=r'[^\\p{L}]+')  # '\\\\W'\n","\n","df3 = regexTokenizer.transform(df)\n","df3.show(truncate=False)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+-----------------------------------------------------+\n","|ID |oracion                                      |palabras                                             |\n","+---+---------------------------------------------+-----------------------------------------------------+\n","|0  |Hola esta prueba es en el año 2021           |[hola, esta, prueba, es, en, el, año]                |\n","|1  |Spark permite clasificación, regresión, etc. |[spark, permite, clasificación, regresión, etc]      |\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|[los, modelos, de, regresión, usan, datos, numéricos]|\n","+---+---------------------------------------------+-----------------------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awthzIfTmuEp","executionInfo":{"status":"ok","timestamp":1637718234882,"user_tz":300,"elapsed":526,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"a384e1a0-6f37-4dcd-b55c-923802fa9d05"},"source":["df3.withColumn('ntokens', countTokens(col('palabras'))).show(truncate=False)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+-----------------------------------------------------+-------+\n","|ID |oracion                                      |palabras                                             |ntokens|\n","+---+---------------------------------------------+-----------------------------------------------------+-------+\n","|0  |Hola esta prueba es en el año 2021           |[hola, esta, prueba, es, en, el, año]                |7      |\n","|1  |Spark permite clasificación, regresión, etc. |[spark, permite, clasificación, regresión, etc]      |5      |\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|[los, modelos, de, regresión, usan, datos, numéricos]|7      |\n","+---+---------------------------------------------+-----------------------------------------------------+-------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"V-PcA7XmGI4B"},"source":["### Stop Words\n","\n","Son palabras que deben ser excluidas de la entrada, usualmente porque aparecen con mucha frecuencia y no contienen mucho significado ni aportan mucha información."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3a3O6J01Ys3","executionInfo":{"status":"ok","timestamp":1637718235809,"user_tz":300,"elapsed":929,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"0f907aae-dc58-406b-bfff-7fcce713a588"},"source":["# Eliminar palabras comunes\n","from pyspark.ml.feature import StopWordsRemover\n","\n","# Remover palabras comunes del idioma español\n","remover = StopWordsRemover(inputCol='palabras', outputCol='palabras filtradas', \n","                           stopWords=StopWordsRemover.loadDefaultStopWords('spanish'))\n","\n","df4 = remover.transform(df3)\n","\n","df4.show(truncate=False)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+-----------------------------------------------------+-----------------------------------------------+\n","|ID |oracion                                      |palabras                                             |palabras filtradas                             |\n","+---+---------------------------------------------+-----------------------------------------------------+-----------------------------------------------+\n","|0  |Hola esta prueba es en el año 2021           |[hola, esta, prueba, es, en, el, año]                |[hola, prueba, año]                            |\n","|1  |Spark permite clasificación, regresión, etc. |[spark, permite, clasificación, regresión, etc]      |[spark, permite, clasificación, regresión, etc]|\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|[los, modelos, de, regresión, usan, datos, numéricos]|[modelos, regresión, usan, datos, numéricos]   |\n","+---+---------------------------------------------+-----------------------------------------------------+-----------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"jLDRZz4xGgR1"},"source":["### N-gramas\n","\n","Un n-grama es una secuencia de $n$ tokens (típicamente palabras) para algún número entero $n$. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3r47n5w83Wie","executionInfo":{"status":"ok","timestamp":1637718236409,"user_tz":300,"elapsed":602,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"4826b0f5-caf8-480f-ef07-8fd0c4446fe4"},"source":["# n-gramas\n","from pyspark.ml.feature import NGram\n","\n","ngram = NGram(n=2, inputCol='palabras', outputCol='ngrama')\n","\n","ngram.transform(df3).show(truncate=False)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+-----------------------------------------------------+------------------------------------------------------------------------------------+\n","|ID |oracion                                      |palabras                                             |ngrama                                                                              |\n","+---+---------------------------------------------+-----------------------------------------------------+------------------------------------------------------------------------------------+\n","|0  |Hola esta prueba es en el año 2021           |[hola, esta, prueba, es, en, el, año]                |[hola esta, esta prueba, prueba es, es en, en el, el año]                           |\n","|1  |Spark permite clasificación, regresión, etc. |[spark, permite, clasificación, regresión, etc]      |[spark permite, permite clasificación, clasificación regresión, regresión etc]      |\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|[los, modelos, de, regresión, usan, datos, numéricos]|[los modelos, modelos de, de regresión, regresión usan, usan datos, datos numéricos]|\n","+---+---------------------------------------------+-----------------------------------------------------+------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bx-wss5h4S9e","executionInfo":{"status":"ok","timestamp":1637718236717,"user_tz":300,"elapsed":309,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}},"outputId":"749e049d-cb00-4626-f336-a7098e697292"},"source":["ngram = NGram(n=3, inputCol='palabras', outputCol='ngrama')\n","\n","ngram.transform(df3).show(truncate=False)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------+-----------------------------------------------------+-----------------------------------------------------------------------------------------------------+\n","|ID |oracion                                      |palabras                                             |ngrama                                                                                               |\n","+---+---------------------------------------------+-----------------------------------------------------+-----------------------------------------------------------------------------------------------------+\n","|0  |Hola esta prueba es en el año 2021           |[hola, esta, prueba, es, en, el, año]                |[hola esta prueba, esta prueba es, prueba es en, es en el, en el año]                                |\n","|1  |Spark permite clasificación, regresión, etc. |[spark, permite, clasificación, regresión, etc]      |[spark permite clasificación, permite clasificación regresión, clasificación regresión etc]          |\n","|2  |Los,modelos,de,regresión,usan,datos,numéricos|[los, modelos, de, regresión, usan, datos, numéricos]|[los modelos de, modelos de regresión, de regresión usan, regresión usan datos, usan datos numéricos]|\n","+---+---------------------------------------------+-----------------------------------------------------+-----------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"id":"CKUkJNXeG2e7","executionInfo":{"status":"ok","timestamp":1637718236968,"user_tz":300,"elapsed":252,"user":{"displayName":"Oscar Efrain Ramos Ponce","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06060603971885071383"}}},"source":[""],"execution_count":11,"outputs":[]}]}